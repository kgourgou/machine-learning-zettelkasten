{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "\n",
    "filenames = glob('../my-markdown-notes/*.md')\n",
    "filenames.remove('../my-markdown-notes/README.md')\n",
    "filenames\n",
    "\n",
    "# load docs into memory\n",
    "docs = []\n",
    "for filename in filenames:\n",
    "    f = open(filename, 'r')\n",
    "    docs.append(f.read())\n",
    "    \n",
    "clean_filenames = [name.split('/')[2].replace('.md','') for name in filenames]\n",
    "clean_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    \"\"\"\n",
    "    Remove urls, linebreaks, dashes, equations, html, etc. \n",
    "    \n",
    "    Most of it is done through regular expressions. \n",
    "    \"\"\"\n",
    "    new_doc = doc.replace('\\n',' ')\n",
    "    \n",
    "    operations = [r'\\$\\$(.+?)\\$\\$',\n",
    "                  r'\\$(.+?)\\$',\n",
    "                  r'\\((.+?)\\)',\n",
    "                 'r\\[(.+?)\\]',\n",
    "                 r'\\#',\n",
    "                 r'---(.+?)---',\n",
    "                 r'[\\*\\-\\_\\\\]',\n",
    "                 r'<[^>]*>']\n",
    "    \n",
    "    \n",
    "    for op in operations:\n",
    "        new_doc = re.sub(op, '', new_doc)\n",
    "\n",
    "    return new_doc\n",
    "\n",
    "new_docs = [preprocess(doc) for doc in docs]\n",
    "message_embeddings = embed(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "  corr = np.inner(features, features)\n",
    "  sns.set(font_scale=1.2)\n",
    "  plt.figure(figsize=(10,10))\n",
    "  g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "  g.set_xticklabels(labels, rotation=rotation)\n",
    "  g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "def run_and_plot(messages_, labels):\n",
    "  message_embeddings_ = embed(messages_)\n",
    "  plot_similarity(labels, message_embeddings_, 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_plot(new_docs, clean_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocSim:\n",
    "    def __init__(self,message_embeddings):\n",
    "        corr = np.inner(message_embeddings, message_embeddings)\n",
    "        np.fill_diagonal(corr,0) # fill diagonal\n",
    "        self.corr = corr\n",
    "        \n",
    "    def rdi(self, index):\n",
    "        \"\"\"\n",
    "        Returns correlated docs\n",
    "        \"\"\"\n",
    "        return self.corr[index,:].argsort()[::-1][0:3]\n",
    "    \n",
    "    def build_graph(self, labels):\n",
    "        \"\"\"\n",
    "        labels for the docs; for example, you can use the \n",
    "        filenames. Should be in the same order as the message embeddings. \n",
    "        \"\"\"\n",
    "        self.graph = {}\n",
    "        for i,name in enumerate(labels):\n",
    "            self.graph[name] = [labels[key] for key in self.rdi(i)]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DocSim(message_embeddings)\n",
    "ds.build_graph(filenames)\n",
    "ds.graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_ in enumerate(clean_filenames):\n",
    "    print(clean_filenames[i])\n",
    "    j = np.argmax(corr[i,:])\n",
    "    print(clean_filenames[j])\n",
    "    print(corr[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
